# /workspace/new_speaker_filter.py (åˆ¤å®šå®‰å®šåŒ–ç‰ˆ: é–¾å€¤ç·©å’Œ & æ­£è¦åŒ–)
import torch
import torchaudio
from speechbrain.inference.classifiers import EncoderClassifier
import os
import logging
import torch.nn.functional as F

logger = logging.getLogger(__name__)

# --- éŸ³å£°èª­ã¿è¾¼ã¿ & å‰å‡¦ç†é–¢æ•° ---
def load_and_normalize_audio(path: str, target_sample_rate=16000):
    if not os.path.exists(path):
        raise FileNotFoundError(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")

    signal, fs = torchaudio.load(path)
    
    # 1. ã‚¹ãƒ†ãƒ¬ã‚ªâ†’ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if signal.shape[0] > 1:
        signal = signal.mean(dim=0, keepdim=True)
    
    # 2. ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (16kHzã¸)
    if fs != target_sample_rate:
        resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=target_sample_rate)
        signal = resampler(signal)

    # 3. â˜…éŸ³é‡æ­£è¦åŒ– (Peak Normalization)â˜…
    # ã“ã‚Œã«ã‚ˆã‚Šã€å£°ã®å¤§ãã•ã«ã‚ˆã‚‹åˆ¤å®šãƒŸã‚¹ã‚’æ¸›ã‚‰ã—ã¾ã™
    max_val = torch.abs(signal).max()
    if max_val > 0:
        signal = signal / max_val
        
    return signal

# --- å£°ç´‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹ ---
class SpeakerGuard:
    def __init__(self):
        print("â³ [SpeakerGuard] ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (SpeechBrain)")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        self.classifier = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="pretrained_models/spkrec-ecapa-voxceleb",
            run_opts={"device": self.device}
        )
        
        self.known_speakers = [] 
        
        # â˜…é–¾å€¤ã‚’å¤‰æ›´â˜…
        # 0.35(å³æ ¼) -> 0.25(å®Ÿç”¨çš„)
        # æ•°å€¤ã‚’ä¸‹ã’ã‚‹ã¨æœ¬äººæ‹’å¦ãŒæ¸›ã‚Šã¾ã™ãŒã€ä»–äººèª¤èªã®ãƒªã‚¹ã‚¯ã¯å°‘ã—å¢—ãˆã¾ã™ã€‚
        # ãƒãƒ©ãƒ³ã‚¹ã‚’è¦‹ã¦ 0.20 ã€œ 0.30 ã®é–“ã§èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
        self.threshold = 0.25 
        
        print(f"âœ… [SpeakerGuard] æº–å‚™å®Œäº† (Device: {self.device}, Threshold: {self.threshold})")

    def extract_embedding(self, audio_tensor):
        """éŸ³å£°æ³¢å½¢ã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«(Embedding)ã‚’æŠ½å‡º"""
        # Tensorã®å½¢çŠ¶ãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒã‚¤ã‚¹ç§»å‹•
        audio_tensor = audio_tensor.to(self.device)
        
        if audio_tensor.ndim == 1:
            audio_tensor = audio_tensor.unsqueeze(0)
            
        # éŸ³é‡æ­£è¦åŒ– (å¿µã®ãŸã‚ã“ã“ã§ã‚‚ãƒã‚§ãƒƒã‚¯)
        max_val = torch.abs(audio_tensor).max()
        if max_val > 0:
            audio_tensor = audio_tensor / max_val

        # é•·ã•æƒ…å ±ã®ãƒ€ãƒŸãƒ¼ä½œæˆ
        wav_lens = torch.ones(audio_tensor.shape[0]).to(self.device)

        with torch.no_grad():
            embedding = self.classifier.encode_batch(audio_tensor, wav_lens)
        
        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™ (ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã®ãŸã‚é‡è¦)
        return F.normalize(embedding, p=2, dim=-1)

    def identify_speaker(self, audio_tensor) -> tuple[bool, str]:
        """
        Tensorã‚’å—ã‘å–ã‚Šã€(ç™»éŒ²æ¸ˆã¿ã‹, è©±è€…ID) ã‚’è¿”ã™
        """
        try:
            current_embedding = self.extract_embedding(audio_tensor)
            
            # ã¾ã èª°ã‚‚ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆ -> æœ€åˆã®1äººã‚’è‡ªå‹•ç™»éŒ² (ã‚ªãƒ¼ãƒŠãƒ¼)
            if not self.known_speakers:
                print("ğŸ”’ [SpeakerGuard] æœ€åˆã®è©±è€…ã‚’ 'User 0' (ã‚ªãƒ¼ãƒŠãƒ¼) ã¨ã—ã¦ç™»éŒ²")
                self.known_speakers.append({'id': 'User 0', 'emb': current_embedding})
                return True, "User 0"

            max_score = -1.0
            best_match_id = "Unknown"
            is_match = False

            # å…¨ç™»éŒ²è€…ã¨æ¯”è¼ƒã—ã€ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’æ¢ã™ (Winner takes all)
            for speaker in self.known_speakers:
                score = torch.nn.functional.cosine_similarity(
                    speaker['emb'], current_embedding, dim=-1
                )
                score_val = score.item()
                
                # ãƒ­ã‚°ã‚’å‡ºã—ã¦èª¿æ•´ã—ã‚„ã™ãã™ã‚‹
                # logger.info(f"Checking {speaker['id']}: Score={score_val:.4f}")

                if score_val > max_score:
                    max_score = score_val
                    best_match_id = speaker['id']

            # æœ€å¤§ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚‹ã‹åˆ¤å®š
            if max_score > self.threshold:
                is_match = True
                logger.info(f"âœ… [SpeakerGuard] èªè¨¼æˆåŠŸ: {best_match_id} (ã‚¹ã‚³ã‚¢: {max_score:.3f} > {self.threshold})")
                return True, best_match_id
            else:
                logger.info(f"ğŸš« [SpeakerGuard] æœªçŸ¥ã®è©±è€… (æœ€å¤§ã‚¹ã‚³ã‚¢: {max_score:.3f} < {self.threshold}) -> å€™è£œ: {best_match_id}")
                return False, "Unknown"
                
        except Exception as e:
            print(f"[SpeakerGuard Error] è­˜åˆ¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False, "Error"

    def register_new_speaker(self, audio_path: str) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰æ–°è¦ç™»éŒ²ã—ã€å‰²ã‚Šå½“ã¦ãŸIDã‚’è¿”ã™
        """
        try:
            # èª­ã¿è¾¼ã¿æ™‚ã«æ­£è¦åŒ–ã‚’å®Ÿè¡Œ
            audio_tensor = load_and_normalize_audio(audio_path)
            
            # æ¥µç«¯ã«çŸ­ã„éŸ³å£°ã®ç™»éŒ²ã‚’é˜²ã (0.5ç§’æœªæº€ã¯ã‚¨ãƒ©ãƒ¼æ‰±ã„ãªã©)
            if audio_tensor.shape[-1] < 8000: # 16000Hz * 0.5s
                print("[SpeakerGuard] ã‚¨ãƒ©ãƒ¼: ç™»éŒ²éŸ³å£°ãŒçŸ­ã™ãã¾ã™")
                return None

            new_emb = self.extract_embedding(audio_tensor)
            
            # IDç”Ÿæˆ
            new_id = f"User {len(self.known_speakers)}"
            
            self.known_speakers.append({'id': new_id, 'emb': new_emb})
            print(f"ğŸ“ [SpeakerGuard] æ–°è¦ç™»éŒ²å®Œäº†: {new_id}")
            return new_id
        except Exception as e:
            print(f"[SpeakerGuard Error] ç™»éŒ²å¤±æ•—: {e}")
            return None

    def verify_tensor(self, audio_tensor):
        """äº’æ›æ€§ç¶­æŒç”¨"""
        is_ok, _ = self.identify_speaker(audio_tensor)
        return is_ok